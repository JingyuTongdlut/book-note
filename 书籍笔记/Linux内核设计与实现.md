<!-- TOC depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 -->

- [Linux设计与实现](#linux设计与实现)
	- [进程管理](#进程管理)
		- [1.进程和线程](#1进程和线程)
		- [2.创建进程](#2创建进程)
		- [3.线程](#3线程)
		- [4.进程终止](#4进程终止)
	- [进程调度](#进程调度)

<!-- /TOC -->
# Linux设计与实现

## 进程管理
### 1.进程和线程
* Linux中的进程于Windows相比是很轻量级的，而且不严格区分进程和线程，线程不过是一种特殊的进程。
* 进程信息都在task_struct中，他由双向循环链表 进行组织。在进程中，通过内核栈底的thread_info结构体中的指针进行访问。
* 内核通过PID来识别每个进程，为pid_t类型。
![进程状态转换](/assets/进程状态转换.png)
* 进程的状态转换图
*进程之间存在着一个明显的进程关系，所有进程均是PID为1的init进程的后代。每个task_struc都有一个指针指向其父进程，还有一个children的子进程链表。
### 2.创建进程
* Linux创建进程分为两步，fork()和exec()。首先通过fork创建一个子进程(和父进程基本一致)，然后通过exec导入可执行文件到地址空间开始运行。
* 写时拷贝
  传统fork将父进程的所有资源复制给子进程，大量的复制导致效率很低。而且，fork常搭配exec使用，这通常会导致拷贝毫无用处(除了浪费时间)。因此，Linux才用了写时复制策略，只有写入时，数据才会被复制，这样fork的开销就只有分配PID以及复制页表。
* fork的步骤
  * dup_task_struct()为进程分配内核栈，thread_info等，值与当前进程相同。
  * check新进程(进程数目是否到上限)。
  * 清楚进程描述符内的各种信息
  * 子进程设置为TASK_UNINTERRUTIBLE确保不会被投入运行。
  * 更新task_struct的flags成员(超级权限清0，没有exec标志设置)
  * 分配新的PID
  * 根据clone的参数，拷贝或者共享打开的文件、文件系统信息、信号处理函数、进程地址空间等。
  * 收尾工作，并返回指向子进程的指针。
### 3.线程
Linux把所有线程当做进程，有自己的task_struct，它看起来就像一个普通的进程，只是共享一些资源。
* 进程创建等价于clone(SIGCHLD, 0)
* 线程调用clone(CLONE_VM | CLONE_FS | CLONE_FILES | CLONE_SIGHAND, 0)，等价于父子两共享地址空间，文件系统资源，文件描述符和信号处理程序。
* 内核需要在后台进行的操作(如flush)，可以通过内核线程去做，内核线程没有独立的地址空间，只能在内核空间运行。
### 4.进程终止
* 由系统调用exit引起的，大部分都要靠do_exit完成
  * 设置task_struct中的标识成员设置为PF_EXITING
  * 调用del_timer_sync()删除内核定时器, 确保没有定时器在排队和运行
  * 调用exit_mm()释放进程占用的mm_struct
  * 调用sem__exit()，使进程离开等待IPC信号的队列
  * 调用exit_files()和exit_fs()，释放进程占用的文件描述符和文件系统资源
  * 把task_struct的exit_code设置为进程的返回值
  * 调用exit_notify()向父进程发送信号，并把自己的状态设为EXIT_ZOMBIE
  * 调用schedule切换到新的进程

  此时，各种资源已经被释放，进程进入僵尸态，**依然占用的资源为内核栈，thread_info以及task_struct**，僵尸态的目的是为了给父进程提供信息，当父进程取走后(或通知内核不关注)，资源全部被释放。
* 孤儿进程
  由于子进程的资源由父进程进行回收，所以当父进程在子进程之前退出时，需要找到新的父亲。
  * 首先在当前线程组找一个线程作为父亲
  * 不行，则让init作为他们的父亲
## 进程调度
### 1.调度原理
* 进程分为IO消耗型和处理器消耗型。
	IO消耗型大部分时间用来提交IO和等待IO请求，因此这类进程经常处于可运行状态，但是只运行一小会儿。
	处理器消耗型大多数时间都用在执行代码上。如果不被抢占，他们通常一直不停的运行。为了效应速度，不应该经常让他们运行，调度器应该**降低调度频率，延长其运行时间**。
* 调度器的平衡
	调度器是在效应迅速和最大系统利用率的平衡。也就是尽量少的切换，和各进程公平使用CPU。
	*结合上面来看，因为IO消耗的CPU时间少，所以可以更积极的调度，这样对于处理器消耗型来说，IO执行的时间才是公平的。*
* 进程的优先级
	* nice值
		范围是-20 ~ 19，nice越低，优先级越高。
	* 实时优先级
		范围是0 ~ 99，越大优先级越高。且任何实时进程的优先级都高于普通进程。

	两个优先级配合，见[两个优先级配合](#anchor1)
* 时间片
	有了优先级，可以决定谁先运行了。但是对于调度程序来说，并不是运行一次就结束了，还必须知道间隔多久进行下次调度。
	于是就有了时间片的概念。时间片是一个数值，表示一个进程被抢占前能持续运行的时间。
	也可以认为是进程在下次调度发生前运行的时间(除非进程主动放弃CPU，或者有实时进程来抢占CPU)。
	时间片的大小设置并不简单，设大了，系统响应变慢(调度周期长)；设小了，进程频繁切换带来的处理器消耗。默认的时间片一般是10ms
### 2.Linux调度算法
Linux在2.6.23内核以后，采用了完全公平调度算法(CFS)。
CFS算法在分配每个进程的CPU时间时，不是分配给它们一个绝对的CPU时间，而是根据进程的优先级分配给它们一个占用CPU时间的百分比。
比如ProcessA(NI=1)，ProcessB(NI=3)，ProcessC(NI=6)，在CFS算法中，分别占用CPU的百分比为：ProcessA(10%)，ProcessB(30%)，ProcessC(60%)
同时，限制了最小粒度为(1ms)，避免过大的切换消耗。
* CFS步骤
	* 计算每个进程的vruntime，通过update_curr()函数更新进程的vruntime。(vruntime是进程虚拟运行时间的总和，是根据可运行进程总数被加权的)
	* 选择具有最小的vruntime的进程进行运行。CFS用红黑树来组织可运行进程，这样可以快速找到最小的数据。
	* 程序运行完后，返回第二步。
	update是由定时器周期更新进程时间的，这样可以准确的给出进程的vruntime。
* 睡眠和唤醒
	当为了等待一些事件时，进程会进入休眠状态。进入时，吧自己从可运行红黑树中删除，加入等待队列，并且调用schedule执行另一个进程。唤醒则相反。
### 3.抢占和上下文切换
* 上下文切换
	当新进程被选出来准备运行时，schedule会调用context_switch，它完成两部分工作
	* 把虚拟内存从上个切换到新进程
	* 将上个进程的处理器状态切换到新的进程处理器状态。(堆栈、寄存器等)

	内核通过need_resched标志表明是否调用schedule。当进程应该被抢占，或者高优先级的进程进入可运行状态，会设置该标志。
* 用户抢占
	从系统调用返回用户空间时
	从中断处理程序返回用户空间时
* 内核抢占
	Linux可以在执行内核级代码的时候重新调度。
	中断处理执行，返回内核空间之前
	内核再次具有可抢占性
	内核代码调用schedule
	内核任务阻塞
### 4.实时调度策略
Linux提供了两种实时调度策略，SCHED_FIFO和SCHED_RR。
* SCHED_FIFO
	先入先出，没有时间片，运行到阻塞。只要有FIFO级别的在进行，其他的低级别进程只能等待它为不可运行后才有机会执行。
* SCHED_RR
	带时间片的FIFO，高优先级能抢占，时间片只对同一优先级有效。
<span id = "anchor1">

实时优先级和nice值配合：
实时优先级为0 ~ MAX_RT_PRO-1，nice值为 MAX_RT_PRO ~ MAX_RT_PRO + nice_max。也就是实时优先级总是高于nice值。
## 系统调用
### 1.系统调用介绍
作为用户和硬件设备的中间层。
* 系统调用的三个意义：
	*	用户程序通过系统调用来使用硬件，而不用关心具体的硬件设备，这样大大简化了用户程序的开发。
	* 保证系统的稳定，可以避免应用程序对硬件进行不必要的操作。
	* 提供访问内核的唯一手段
### 2.系统调用实现原理
* 通知内核
	通过软中断的形式(引发一个异常)来切换到内核态执行系统调用处理程序X86通过`int $0x80`实现
* 告知系统调用号
	陷入内核后，还需要将系统调用号传递给内核，X86通过eax进行传递。
* 参数传递
	通过五个寄存器存放五个参数，超过的部分用一个单独的寄存器指向存放所有参数在用户空间地址的指针。
* 系统调用返回值
	向用户空间传递返回值也通过寄存器，X86中通过eax。
## 中断和中断处理
### 1.什么是中断
中断为了提高CPU和外围设备的协同性能，当硬件需要时，想CPU发送信号，CPU进行相应的机制。本质上是由于CPU的速度和外围硬件设备速度差距较大而产生的一种处理手段。

特定的中断和特定的设备相绑定。
### 2.中断相关流程
* 中断处理程序(ISR)
	在响应特定中断时，内核会执行中断处理程序，每个特定的中断都有一个对应的中断处理程序，它是设备驱动的一部分。
* 上半部和下半部
	因为对硬件来说，希望尽快被中断服务，但对其他部分来说，希望尽可能短的运行完中断历程。因此，把处理切为两部分，有严格时限的在ISR中完成，能够稍微推后的，放在下半部执行。
* 中断实现相关
	* 注册中断函数
	* 释放中断的函数
	* 中断处理函数的声明
## 下半部和推后执行的工作
### 1.下半部处理
* 任务到底在上下哪部分完成，取决于驱动开发者自己的判断。有一些提示可以借鉴：
	* 时间敏感，放在中断处理程序
	* 硬件相关，放在中断处理程序
	* 保证不被其他中断打断，放在中断处理程序
	* 其他，放在下半部
* 下半部实现方法
	* 软中断
	* tasklet
	* 工作队列
	* 定时器(用于推后到特定时间运行)
### 2.软中断
* 软中断的特点
	* 编译器静态分配(上限32)
	* 不互相抢占
	* 只有中断可以抢占
	* 可以在其他处理器同时执行
* 软中断执行
	注册的软中断在标记后才会执行，称为触发软中断，然后在合适的时候会被检查和执行
	* 硬件中断代码处返回时
	* 在ksoftirqd内核线程中
	* 显示的检查中
### 3.tasklet
tasklet是利用软中断实现的一种下半部机制，由两类软中断代表(HI_SOFTIRQ高优先级和TASKLET_SOFTIRQ低优先级)。除非对性能要求特别高，否则推荐使用tasklet实现自己的中断。
```
struct tasklet_struct
{
    struct tasklet_struct *next; /* 链表中的下一个tasklet */
    unsigned long state;         /* tasklet状态 */
    atomic_t count;              /* 引用计数器 */
    void (*func)(unsigned long); /* tasklet处理函数 */
    unsigned long data;          /* tasklet处理函数的参数 */
};
```
state有0没有调度，TASKLET_STATE_SCHED表示被调度还有TASK_STATE_RUN表示已经运行。count不为0表示tasklet被禁止。
* tasklet调度
	在中断上半部处理完后，调度tasklet，会对状态进行检查，然后将需要调度的task_let分配到每个处理器的tasklet_vec中，最后唤醒对应软中断，下半部会在合适的时候被处理。
### 4.工作队列
工作队列子系统是一个用于创建内核线程的接口，通过它可以创建一个工作者线程来专门处理中断的下半部工作。

工作队列和tasklet不一样，不是基于软中断来实现的，处于进程上下文中，唯一能够休眠的方式。
缺省的工作者线程名称是 events/n (n对应处理器号)。
* 流程
	* 创建推后执行的工作(静态、动态)
	* 刷新现有的工作(确保已有工作完成，非必须)
	* 调度，唤醒工作者线程。
## 内核同步方法
### 1.原子操作
原子操作保证执行过程不被打断的运行。
* 原子操作有两类
	* 整数，包括32位和64位
	* 原子位操作
### 2.自旋锁
原子操作只能用于临界区只有一个变量的情况，实际应用中，临界区的情况要复杂的多。
对于复杂的临界区，linux内核中也提供了多种同步方法，自旋锁就是其中一种。
* 自旋锁特点
	自旋锁的特点就是当一个线程获取了锁之后，其他试图获取这个锁的线程一直在循环等待获取这个锁，直至锁重新可用。
	由于线程实在一直循环的获取这个锁，所以会造成CPU处理时间的浪费，因此最好将自旋锁用于能很快处理完的临界区。
* 注意事项
	* 自旋锁不可递归
	* 线程获取自旋锁前，要禁止当前处理器的中断，防止获取锁的线程和中断竞争
* 在下半部使用自旋锁要注意：
	* 下半部处理和进程上下文共享数据时，由于下半部的处理可以抢占进程上下文的代码，所以进程上下文在对共享数据加锁前要禁止下半部的执行，解锁时再允许下半部的执行。
	* 中断处理程序（上半部）和下半部处理共享数据时，由于中断处理（上半部）可以抢占下半部的执行，所以下半部在对共享数据加锁前要禁止中断处理（上半部），解锁时再允许中断的执行。
	* 同一种tasklet不能同时运行，所以同类tasklet中的共享数据不需要保护。
	* 不同类tasklet中共享数据时，其中一个tasklet获得锁后，不用禁止其他tasklet的执行，因为同一个处理器上不会有tasklet相互抢占的情况
	* 同类型或者非同类型的软中断在共享数据时，也不用禁止下半部，因为同一个处理器上不会有软中断互相抢占的情况
### 4.读写锁
读写自旋锁除了和普通自旋锁一样有自旋特性以外，还有以下特点
* 读锁之间是共享的
* 写锁之间互斥
* 读写锁之间是互斥的
**不能把一个读锁升级为写锁，会死锁**
### 5.信号量
信号量也是一种锁，和自旋锁不同的是，线程获取不到信号量的时候，不会像自旋锁一样循环的去试图获取锁，而是进入睡眠，直至有信号量释放出来时，才会唤醒睡眠的线程，进入临界区执行。

信号量有二值信号量和计数信号量2种，其中二值信号量比较常用。二值信号量表示信号量只有2个值，即0和1。信号量为1时，表示临界区可用，信号量为0时，表示临界区不可访问。

计数信号量有个计数值，比如计数值为5，表示同时可以有5个线程访问临界区。
### 6.互斥体
互斥体也是一种可以睡眠的锁，相当于二值信号量，只是提供的API更加简单，使用的场景也更严格一些，如下所示：
* mutex的计数值只能为1，也就是最多只允许一个线程访问临界区
* 在同一个上下文中上锁和解锁
* 不能递归的上锁和解锁
* 持有个mutex时，进程不能退出
* mutex不能在中断或者下半部中使用，也就是mutex只能在进程上下文中使用
* mutex只能通过官方API来管理，不能自己写代码操作它
### 7.顺序锁
顺序锁为读写共享数据提供了一种简单的实现机制。
之前提到的读写自旋锁和读写信号量，在读锁被获取之后，写锁是不能再被获取的，
也就是说，必须等所有的读锁释放后，才能对临界区进行写入操作。

顺序锁则与之不同，读锁被获取的情况下，写锁仍然可以被获取。
使用顺序锁的读操作在读之前和读之后都会检查顺序锁的序列值，如果前后值不符，则说明在读的过程中有写的操作发生，
那么读操作会重新执行一次，直至读前后的序列值是一样的。
**适用于写优先于读的场景**
### 8.禁止抢占
其实使用自旋锁已经可以防止内核抢占了，但是有时候仅仅需要禁止内核抢占，不需要像自旋锁那样连中断都屏蔽掉。

这时候就需要使用禁止内核抢占的方法了：
preempt_disable()和preempt_enable()是可以嵌套调用的，disable和enable的次数最终应该是一样的。
### 9.顺序和屏障
在某些并发情况下，为了保证代码的执行顺序，引入了一系列屏障方法来阻止编译器和处理器的优化。
	rmb()	阻止跨越屏障的载入动作发生重排序
	read_barrier_depends()	阻止跨越屏障的具有数据依赖关系的载入动作重排序
	wmb()	阻止跨越屏障的存储动作发生重排序
	mb()	阻止跨越屏障的载入和存储动作重新排序
	smp_rmb()	在SMP上提供rmb()功能，在UP上提供barrier()功能
	smp_read_barrier_depends()	在SMP上提供read_barrier_depends()功能，在UP上提供barrier()功能
	smp_wmb()	在SMP上提供wmb()功能，在UP上提供barrier()功能
	smp_mb()	在SMP上提供mb()功能，在UP上提供barrier()功能
	barrier()	阻止编译器跨越屏障对载入或存储操作进行优化
![内核同步方法总结](/assets/内核同步方法总结.png)
## 定时器和时间管理
### 1.系统时间
* 实际时间
	实际时间的获取是在开机后，内核初始化时从RTC读取的。内核读取这个时间后就将其放入内核中的 xtime 变量中，并且在系统的运行中不断更新这个值。
	调用gettimeofday系统调用获得
* 定时器
	定时器是内核中主要使用的时间管理方法，通过定时器，可以有效的调度程序的执行。
	动态定时器是内核中使用比较多的定时器，下面重点讨论的也是动态定时器。
### 2.时钟中断处理程序
时钟中断处理程序作为系统定时器而注册到内核中，体系结构的不同，可能时钟中断处理程序中处理的内容不同。
但是以下这些基本的工作都会执行：
* 获得 xtime_lock 锁，以便对访问 jiffies_64 和墙上时间 xtime 进行保护
* 需要时应答或重新设置系统时钟
* 周期性的使用墙上时间更新实时时钟
* 调用体系无关的时钟历程，tick_periodic
### 3.定时器流程
* 使用定时器
	定时器在内核中由一个链表来保存的
	```
	struct timer_list {
    struct list_head entry; //定时器链表入口
    unsigned long expires; //jiffies为单位的定时值

    void (*function)(unsigned long); //处理函数
    unsigned long data; //参数

    struct tvec_base *base; //内部使用
	};
	```
	* 初始化定时器init_timer
	* 设置定时器到期时间，回调函数
	* 激活定时器
* 定时器组织
	定时器作为软中断，在中断下半部上下文中执行。定时器以链表形式进行组织，但遍历代价太大。内核将他们的超时时间划分为五组。
* 延迟执行
	* 忙等待
		通过循环进行等待，忙等待，效率太低。
	* schedule_timeout()
		会让指定任务休眠到延迟耗尽才重新运行。
## 内存管理
### 1.内存管理单元
* 页
	内存管理单元(MMU)以页为基本单位，通常为4K或者8k。
	物理页用struct page表示，结构如下
	```
	struct page {
		unsigned long flags; //页的状态
		atomic_t _count; //页的引用计数
		atomic_t _mapcount; //映射到mms的pte个数
		unsigned long private; //此page作为私有数据时，指向私有数据
		struct addredd_space *mapping; //作为页缓存时，指向关联的address_space
		pgoff_t index; //
		struct list_head lru; //将页关联起的
		void *virtual; //页的虚拟地址
	}
	```
* 区
	由于硬件限制，不是所有页对内核都一样，因此，内核将内存分为不同的区。
	一般关注3个：
	* ZONE_DMA，DMA使用的页，<16MB
	* ZONE_NORMAL 正常可寻址的页 16-896MB
	* ZONE_HIGHMEM 动态映射的页 >896MB

	某些硬件只能直接访问内存地址，不支持内存映射，对于这些硬件内核会分配 ZONE_DMA 区的内存。
	某些硬件的内存寻址范围很广，比虚拟寻址范围还要大的多，那么就会用到 ZONE_HIGHMEM 区的内存，
### 2.内存获取方法
* 按页获取
	根据提供的API，获取，释放页
* 按字节获取
	kmalloc和vmalloc。区别在于kmalloc申请的物理空间是连续的，vmalloc不是，但是二者虚拟空间都是连续的。
	应该尽量使用kmalloc，因为物理上连续，性能较好，因为不需要为每页建立虚拟地址。由于不连续，vmalloc会产生大得多的TLB抖动。
### 3.slab层
频繁的分配/释放内存会导致系统性能的下降，所以内核为频繁分配/释放的对象建立了缓存。
* slab层原理
	linux中的高速缓存是用所谓 slab 层来实现的，slab层即内核中管理高速缓存的机制。
	slab层原理如下：
	* 可以在内存中建立各种对象的高速缓存(比如进程描述相关的结构 task_struct 的高速缓存)
	* 除了针对特定对象的高速缓存以外，也有通用对象的高速缓存
	* 每个高速缓存中包含多个 slab，slab用于管理缓存的对象
	* slab中包含多个缓存的对象，物理上由一页或多个连续的页组成
	![slab层](/assets/slab层.png)
* slab应用
slab结构体的定义参见：mm/slab.c
```
struct slab {
    struct list_head list;   /* 存放缓存对象，这个链表有 满，部分满，空 3种状态  */
    unsigned long colouroff; /* slab 着色的偏移量 */
    void *s_mem;             /* 在 slab 中的第一个对象 */
    unsigned int inuse;         /* slab 中已分配的对象数 */
    kmem_bufctl_t free;      /* 第一个空闲对象(如果有的话) */
    unsigned short nodeid;   /* 应该是在 NUMA 环境下使用 */
};
```
slab层的应用主要有四个方法：
* 高速缓存的创建
* 从高速缓存中分配对象
* 向高速缓存释放对象
* 高速缓存的销毁
### 4.获取高端内存
高端内存就是之前提到的 ZONE_HIGHMEM 区的内存。

在x86体系结构中，这个区的内存不能映射到内核地址空间上，也就是没有逻辑地址，

为了使用 ZONE_HIGHMEM 区的内存，内核提供了永久映射和临时映射2种手段：
* 永久映射
	永久映射可以睡眠，因此只能用在进程上下文中
```

/* 将 ZONE_HIGHMEM 区的一个page永久的映射到内核地址空间
 * 返回值即为这个page对应的逻辑地址
 */
static inline void *kmap(struct page *page)

/* 允许永久映射的数量是有限的，所以不需要高端内存时，应该及时的解除映射 */
static inline void kunmap(struct page *page)
```
* 临时映射
临时映射不会阻塞，也禁止了内核抢占，所以可以用在中断上下文和其他不能重新调度的地方。
```
/**
 * 将 ZONE_HIGHMEM 区的一个page临时映射到内核地址空间
 * 其中的 km_type 表示映射的目的，
 * enum kn_type 的定义参见：<asm/kmap_types.h>
 */
static inline void *kmap_atomic(struct page *page, enum km_type idx)

/* 相应的解除映射是个宏 */
#define kunmap_atomic(addr, idx)    do { pagefault_enable(); } while (0)
```
## 进程地址空间
### 1.地址空间
地址空间就是每个进程所能访问的内存地址范围。
这个地址范围不是真实的，是虚拟地址的范围，有时甚至会超过实际物理内存的大小。

地址空间就是每个进程所能访问的内存地址范围。
这个地址范围不是真实的，是虚拟地址的范围，有时甚至会超过实际物理内存的大小。

内存区域包含以下信息：
* 代码段，可执行文件代码的内存映射
* 数据段，可执行文件的已初始化的全局变量的内存映射
* bss段的零页，未初始化的全局变量的内存映射
* 进程用户空间栈的零页的内存映射
* 进程使用的C库或者动态链接库等共享库的代码段，数据段和bss段的内存映射
* 任何内存映射文件
* 任何共享内存段
* 任何匿名内存映射，比如由 malloc() 分配的内存

内核用mm_struct描述一个进程的空间。
### 2.虚拟内存区域(VMA)
内存区域由vm_area_struct表示，描述了连续空间上的一个独立内存范围，一个VMA代表一种类型的内存区域(比如用户空间栈等)。

内核通过mmap和munmap创建和删除地址区间。
### 3.页表
地址空间中的地址都是虚拟内存中的地址，而CPU需要操作的是物理内存，所以需要一个将虚拟地址映射到物理地址的机制。
这个机制就是页表，linux中使用3级页表来完成虚拟地址到物理地址的转换。
**多级页表和页表**：采取一级页表，则需要很大的连续内存来存放所有的页表项，占用空间大。采取多级列表，可以用更小的内存表示所有内存空间，在下级列表中，没有被使用的可以直接不存放，节省了空间。
但是使用多级列表会造成访问内存次数的增加，花费时间也因此增加。
1. PGD - 全局页目录，包含一个 pgd_t 类型数组，多数体系结构中 pgd_t 类型就是一个无符号长整型

2. PMD - 中间页目录，它是个 pmd_t 类型数组

3. PTE - 简称页表，包含一个 pte_t 类型的页表项，该页表项指向物理页面

虚拟地址-页表-物理地址关系如下图
![多级页表](/assets/多级页表.png)
由于在内存中查找的速度有限，所以一般体系结构都实现了一个翻译后缓冲器(TLB)，当请求发生时，首先会在TLB中查找是否缓存了该映射。
## 页高速缓存和页回写
### 1.缓存简介
* 磁盘高速缓存
	* 磁盘和内存访问速度的巨大差异
	* 临时局部性原理
* 读操作
	读操作检查缓存是否存在要读取的内容即可
* 写操作
	写缓存因为涉及到缓存内容和磁盘内容同步的问题，所以要复杂的多。
	常见的有三种策略：
	* 不缓存：当对缓存数据数据更改时，直接写入磁盘，同时使此缓存失效。(太低效，基本不用)
	* 写透缓存：同时更新缓存和磁盘
	* 回写：写数据时写到缓存，由另一个进程合适的时候进行同步。
* 缓存回收策略
	* 最近最少使用(LRU) :: 每个缓存数据都有个时间戳，保存最近被访问的时间。回收缓存时首先回收时间戳较旧的数据。
	* 双链策略(LRU/2) :: 基于LRU的改善策略。
		双链策略其实就是 LRU(Least Recently Used) 算法的改进版。
		它通过2个链表(活跃链表和非活跃链表)来模拟LRU的过程，目的是为了提高页面回收的性能。
		页面回收动作发生时，从非活跃链表的尾部开始回收页面。
### 2.页回写
linux 页高速缓存中的回写是由内核中的一个线程(flusher 线程)来完成的，flusher 线程在以下3种情况发生时，触发回写操作。
1. 当空闲内存低于一个阀值时

	空闲内存不足时，需要释放一部分缓存，由于只有不脏的页面才能被释放，所以要把脏页面都回写到磁盘，使其变成干净的页面。

2. 当脏页在内存中驻留时间超过一个阀值时

   确保脏页面不会无限期的驻留在内存中，从而减少了数据丢失的风险。

3. 当用户进程调用 sync() 和 fsync() 系统调用时

   给用户提供一种强制回写的方法，应对回写要求严格的场景。

flusher线程的实现：
* bdflush和kupdate共同完成
	bdflush处理内存消耗到特定阈值以下时的情况
	kupdate周期性的运行，写回脏页。
	**当不写任务较重，只有一个bdflush，可能会导致阻塞**
* pdflush
	pdflush 线程数目是动态的，取决于系统的I/O负载。它是面向系统中所有磁盘的全局任务的。
	**有可能多个pdflush阻塞在同一个磁盘上，导致其他的不能及时运行**
* flusher线程
	数目动态，并且每个flusher对应与一个磁盘
