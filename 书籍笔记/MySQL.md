# MySQL 基础
## 基础结构
![mysql基本结构](../assets/mysql基本结构.png)
mysql整体架构分为两部分：Server 层和存储引擎层，除了存储之外的功能，基本都在 Server 层进行实现。  
存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。

**不建议使用查询缓存**：虽然缓存命中，看上去很美好，但是，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能费很大力气存的缓存，还没使用呢，就被一个更新全清空了。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。(ps:8.0 版本开始，缓存功能被删掉了。。。)

## 日志系统

### redo log(innodb 引擎层 crash-safe)

redo log 记录了修改的流水账形势的日志，mysql更新时会先修改 redo log的内容，在适当的时候(比较空闲的时候)将操作记录更新到磁盘上。

redo log 的大小是有限的，当写满的话，就需要先将记录的数据写入磁盘才行(相当于每次只记录了 redo log，磁盘的文件并没有改变)。

有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 crash-safe。

当数据写入redo log之后，数据最终怎么写入到磁盘的呢？这就涉及到数据库中的WAL技术，WAL的全称是Write-Ahead Logging，它的关键点就是先写日志，再写磁盘。为什么需要先写入redo log，而不是直接写入磁盘？写入磁盘只写入一次，而写redo log再写磁盘需要写入两次，这个就需要了解磁盘的写入过程。
在磁盘中，如果直接写入话，需要随机io进行读写，而磁盘中磁头相对于cpu的速度又太慢了，而每次事物进行commit都需要随机io。redo log是顺序写入，相对于随机写入过程则快了数倍。

redo log 显然也需要持久化，mysql 可以通过 innodb_flush_log_at_trx_commit的值来确定。
* 0：每秒写入 os buffer，并调用 fsync 刷到磁盘
* 1：每次提交到 osbuffer，并 fsync
* 2：每次提交写入 osbuffer，每秒 fsync

### binlog

由于redo log 是innodb 引入的，mysql 自带的引擎之前的 myisam 是没有crash safe 能力的，因此后来的 innodb 引擎就加入了 redo log 来实现。

sync_binlog = { 0 | n } #这个参数直接影响mysql的性能和完整性
sync_binlog=0:不同步，日志何时刷到磁盘由FileSystem决定，这个性能最好。
sync_binlog=n:每写n次binlog日志事件(不是事务)，MySQL将执行一次磁盘同步指令fdatasync()将缓存日志刷新到磁盘日志文件中。

### redo log vs binlog
1. redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。
2. redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。
3. redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

### update 语句流程图

update 语句的执行流程图，图中浅色框表示是在 InnoDB 内部执行的，深色框表示是在执行器中执行的。
![update语句流程](../asserts/../assets/update语句流程.png)

**两阶段提交**：
先更新 redo log,然后更新 binlog，再提交事务，redo log处于 commit 状态。

如果不使用两阶段提交，可能会出现 redo log 和 binlog 不一致的状况。

这里可能有人觉得会有问题，如果在写完 binlog，然后 redolog 提交前失败了，那么重启的时候，不会有问题吗。其实不会的，因为 redolog 会根据 binlog 来检验这个是否应该被提交。

binlog 由于是追加记录，因此记录的是全量操作，因此可以用来恢复数据库，以及扩容。

之所以有 binlog，主要是用户有可能不用 innodb，且redolog是循环写的，不持久保存

## 事务

### ACID

先介绍一下事务的几个特性：
* 原子性(Atomicity)：原子性指的是事务的每个步骤是一起的，要么全部完成，要么全部没做。
* 一致性(Consistency)：数据库从一种一致性状态，变为下一种一致性状态，数据库的完整性约束没有受到破坏。事务可以有不同的一致性状态：
  * 强一致性：无论更新操作在哪个副本，之后的读都能获取最新的数据。
  * 弱一致性：提交的更新操作，不一定立刻被读到，需要一段时间。
  * 最终一致性：如果没有其他事物更新同样的位置的话，最终所有的事物都会读到最新值。
* 隔离性(Isolation)：要求每个读写事物对其他事物的操作对象能相互分离，以保证不同事务可以正常工作。隔离性有多个级别，见下表：

    | 隔离级别 |   脏读   | 不可重复读 |   幻读   |
    | :------: | :------: | :--------: | :------: |
    | 读未提交 | $\surd$  |  $\surd$   | $\surd$  |
    | 读已提交 | $\times$ |  $\surd$   | $\surd$  |
    | 可重复读 | $\times$ |  $\times$  | $\surd$  |
    | 可串行化 | $\times$ |  $\times$  | $\times$ |
    
    首先介绍一下四个隔离级别：
    * 读未提交：一个事务还未提交，变更就会被其他事务看到。
    * 读提交：一个事务提交之后，它做的变更才会被其他事务看到。
    * 可重复读是指：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。
    * 串行化：顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能技术研发类继续执行。
    ```
    读未提交：别人改数据的事务尚未提交，我在我的事务中也能读到。
    读已提交：别人改数据的事务已经提交，我在我的事务中才能读到。
    可重复读：别人改数据的事务已经提交，我在我的事务中也不去读。
    串行：我的事务尚未提交，别人就别想改数据。
    ```

    因此，几种对应的现象为：
    * 脏读：一个事务访问到了另一个事务未提交的数据
    * 幻读：一个事务读取两次，得到记录条数不一致
    * 不可重复读：一个事务读取同一记录两次，得到结果不一致

    隔离的实现：
    数据库通过多版本并发控制(MVCC)来提升并发性，MVCC 是通过保存数据在某一时刻的快照实现的。具体来说，innodb 在每行加入了两列，分别是创建版本号和过期版本号(版本号每次新的事务+1)。MVCC 只在读提交和可重复读两个级别使用。可以参考[MVCC多版本](https://www.cnblogs.com/chinesern/p/7592537.html)


* 持久性(Durability)：事务一旦提交，结果就是永久性的。 

## 索引

### 索引模型

索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。有不同的数据结构可以实现高效的查询，常见的有哈希表、有序数组和搜索树。

* 哈希表
    查找快，但是因为只有等值操作，因此对于范围查询，很慢。适用于只有等值查询的场景，比如 Memcached 及其他一些 NoSQL引擎。
* 有序数组
    等值及范围查询都很快，但是插入效率很低，适用于静态存储引擎，比如一些不再修改的数据。
* 二叉搜索树
    各方面效率高，但因为索引要写到磁盘上，所以二叉就不那么合适了，因此一般采用N叉树
* B+树
    见实习笔记 4.B树，B+树

### innodb 索引

innodb 采用的是 B+树的索引模型，根据叶子节点的内容，索引类型分为主键索引和非主键索引。

主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。

非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。

因此，在查询时，主键直接查询的是主键对应的 B+树，而查询其他索引则是先查询索引树得到主键 ID，再去主键对应的树里查询内容(称为回表)。

因为B+树的出度公式如下：
$$d_{max}=floor({pagesize \over keysize+datasize+pointsize})$$
因为 B+树删除了 datasize 的大小，因此出度可以做的更大，更扁平。想要调整的话，可以通过调整 pagesize 的大小，来提高出度上限。

**索引重建**：索引可能因为删除，或者页分裂等原因，导致数据页有空洞，重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高，也就是索引更紧凑、更省空间。重建可以用`alter table T drop primary key;alter table T add primary key(id);`，需要注意，这种方式，重建普通索引是可行的，重建主键不行，因为删除或添加主键，都会重建整个表，效率太低。主键可以用`alter table T engine=InnoDB`

### 联合索引

假设建立(a, b)的联合索引，建立 B+树的排序根据先按 a 排大小，一样再按 b 排序。这就导致，在全局来看 a 是有序的，而 b 是无序的。只有当a 固定时，b 才在局部显示出有序性。

**最左原则**：因为这个建立的过程，因此 mysql 在匹配的时候，符合最左原则，也就是在检索数据时，从联合索引的最左边开始匹配，此外，当出现比较符合时，后续的索引将不能生效。

相关题目看[mysql联合索引](https://mp.weixin.qq.com/s?__biz=MzIwMDgzMjc3NA==&mid=2247484811&idx=1&sn=fb702f90cdd86f5139a857b933bf438f&chksm=96f667e2a181eef4443f08cf380b0a02a38a4f08e6ff0faf69df63e6cfac8ca7babddcfac16f&token=239858186&lang=zh_CN#rd)

**索引下推优化**：在5.6 之前，根据最左原则匹配后，就会回表进行查询了，MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。

### 索引覆盖

因为索引需要回表进行查询，但如果是那种根据索引查找主键的需求的话，在索引树就可以直接得到了，这种现象叫做索引覆盖。

如果有高频的需求根据 a 查 b，则可以通过建立联合索引的方式，减少回表，提高效率。

### 普通索引和唯一索引

根据索引的 B+树，我们可以知道：
* 对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。
* 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。

但是由于 mysql 是一页一页读取的，因此在内存里多读一个数造成的区别微乎其微。

真正让他俩有区别的地方在于跟 change buffer 相关的部分。因为唯一索引需要对唯一性进行验证，所以必须要读入内存才能判断(使用不了 change buffer)，因此普通索引反而效率更高。

*change buffer:当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。*(**因为唯一索引需要读入内存判断是否唯一，因此只有普通索引可以使用**)

更新数据时，mysql 有
* 在内存中：则直接更新内存的数据
* 不再内存中，唯一索引需要将页读入内存，判断后再插入，普通索引使用 change buffer

## 并发

### 全局锁

全局锁就是对整个数据库实例加锁，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。

全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都 select 出来存成文本。

`set global readonly=true`也可以设置库位只读，但是当连接意外断开时，操作不会复位，因此不如 FTWRL 方法。

### 表级锁

表锁一般是在数据库引擎不支持行锁的时候才会被用到的

1. 表锁
    `lock tables tablename read/write`，需要注意表锁除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。也就是说执行了上述语句的线程，讲只能对 tablename 进行操作，且只能执行 lock 对应的操作，直到主动 unlock，或者连接断开。

    **对于 InnoDB 这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发，毕竟锁住整个表的影响面还是太大。**

2. 元数据锁(meta data lock)
    MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。

    当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。
    * 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。
    * 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。

### 行锁

行锁是在引擎层面实现的，myisam 不支持行锁，innodb 支持行锁。因为 myiasm 不支持行锁，所以在更新时需要锁住整个表，影响系统并发度。

**两阶段协议**：在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。(因此，如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。)

### 死锁和死锁检测

并发显然会有着死锁的问题，mysql 有两种策略：
* 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。
* 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。

由于超时时间难以设置，因此一般采用死锁检测的方法。

但是死锁检测每次都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 O(n) 的操作，假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此，你就会看到 CPU 利用率很高，但是每秒却执行不了几个事务。(**控制并发度可以降低时间，对于相同行的更新，在进入引擎层前进行排队**)

### 一致性视图

首先，事务的起点不是 begin transaction，而是第一个操作 innoDB 的语句。

* 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；
* 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。

InnoDB 里面每个事务都有唯一的一个 id，而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。下图为多个事务连续更新后的状态。
![innodb视图](../assets/innodb视图.png)

实际上，图 2 中的三个虚线箭头，就是 undo log；而 V1、V2、V3 并不是物理上真实存在的，而是每次需要的时候根据当前版本和 undo log 计算出来的。比如，需要 V2 的时候，就是通过 V4 依次执行 U3、U2 算出来。

在事务启动时，innodb 位每个事务构造了一个数组，用来保存，启动瞬间，正在活跃的事务 id。根据 row_trx_id，row_trx_id 分为以下几类
![数据版本可见性](../assets/数据版本可见性.png)
有以下规则：
1. 绿色可见，红色不可见
2. 中间部分，如果 row_trx_id 在当前事务的事务数组中，则说明还未提交，不可见
3. 不再事务数组中，说明一件提交啦，可以读到。

**更新逻辑**：
在读的时候，只能根据上述规则读取，因此事务开始后提交的部分肯定是读取不到，但是，如果进行更新数据，那么就不能再历史数据上更新了，否则会丢失掉其他事务的更新。所以，这里就用到了这样一条规则：**更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）**。


### 隔离分析

1. 读取逻辑

一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：
* 版本未提交，不可见；
* 版本已提交，但是是在视图创建后提交的，不可见；
* 版本已提交，而且是在视图创建前提交的，可见。

1. 更新逻辑

在更新的时候，和读取不一样，不能基于历史版本更新，那样之前有的 commit 可能就丢失了。因此，更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”。(select 加锁的话，也是当前读)

1. 读提交和可重复读的区别

* 在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；
* 在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。