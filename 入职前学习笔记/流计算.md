# 1. 流计算概述

## 1.1 概述

根据数据的变化规律，用于分析的数据主要有这么两类：

* 静态数据：比如 hive 这种数据仓库，经过 ETL 过程后，数据是不可改变的，分析人员可以反复基于这种静态数据做分析
* 流数据：数据不是一成不变的，而是以大量、快速、时变的流形式持续的到达

之所以有这两种数据，本质上是因为他们对应这两种不同形式的计算策略：

* 批量计算：充裕时间处理海量静态数据
* 实时计算：产生数据后，需要实时的进行跟踪分析，并且迅速的给出分析结果。比如用户进行了点击之后，平台肯定希望立刻对用户推荐内容进行更新，因为如果几分钟后再进行更新，可能用户已经满足了上一个需求了。



流数据的特点：

* 数据快速持续到达，潜在大小可能是无尽的
* 数据来源众多
* 数据量大，但是并不十分关注存储，一旦经过处理，很大部分被丢弃，有一部分可能会被归档存储
* 注重数据的整体价值，不过分关注个别数据

<center>
  <img src="/Users/jingyu/Documents/GitHub/book-note/assets/image-20210112094601063.png" alt="image-20210112094601063" style="zoom:50%;" />
</center>

流计算的处理流程如上图，分为三个步骤：

* 数据实时采集：采集多个数据源的海量数据，需要保证实时性、低延迟，以日志数据为代表，需要汇总来自不同机器上的日志数据，可以使用 flume、kafka 等。
* 数据实时计算：对采集的数据进行实时的分析和计算，并实时反馈结果。处理后的数据可以进行存储，或者直接丢弃
* 实时查询服务：经过流计算框架得出的结果可供用户进行实时查询、展示或存储。与传统的流程相比，实时查询可以不断的更新结果，并将用户所需的结果实时的推送给用户



看了下清华的视频，讲的好，流计算的本质在于如果一个 x 的增量操作可以表示为：
$$
F(X + \triangle X)=F(X)opH(\triangle X)
$$
如果可以表示，那么我们可以将之前的计算结果 F(X) 保存下来，并且和增量的运算结果进行合并。这种不断以增量方式流入系统并且处理，改变系统状态并且输出结果的形式就叫做流计算。

## 1.2 流计算的实现

### 1.2.1 (worker + queue) 

实现架构上主要分为两部分：

* worker：处理单元
* queue：缓冲+路由，一方面，队列可以起到缓冲的作用(其实就是削峰，或者滤波)，另一方面，队列可以起到路由的作用，决定流向哪个消费者。

<img src="/Users/jingyu/Documents/GitHub/book-note/assets/image-20210112194406045.png" alt="image-20210112194406045" style="zoom: 33%;" />

实现流程如上图，数据源首先被推送到一些 queue 上，然后一堆 worker 会对数据源进行处理，最后将 url 映射到一个固定的 queue 中(为了降低后续写数据库时的冲突)，再由一组 worker 来对数据库数据进行更改。这中直观的实现有着不少问题：

* 首先是为了实现将 url 映射到固定的 queue，通常会采用 hash，这导致系统的扩展性很不好
* 此外，某一个 queue 如果挂掉，由于有一些 url 固定的发送到这个 queue，因此容错性也很差

# 2. flink

<img src="/Users/jingyu/Documents/GitHub/book-note/assets/image-20210330103651056.png" alt="image-20210330103651056" style="zoom:50%;" />

Flink 架构如上图所示，他是一个分布式系统，可以运行在本地，也可以以集群模式运行，还可以作为 YARN 等框架的应用程序，在其集群中运行。在部署上层是 flink 的执行引擎和 API，此外，flink 还提供了一些计算相关的库。

## 2.1 流处理架构

<img src="/Users/jingyu/Documents/GitHub/book-note/assets/image-20210330153015802.png" alt="image-20210330153015802" style="zoom:50%;" />

典型的流处理应用结构如上图，分为

* 消息传输层：采集连续事件产生的数据，传输给订阅的消费者消费，通常采用 kafka。作为流处理应用中关键的一环，消息传输层应该满足：
  * 高性能和持久性兼得
  * 解耦生产者和消费者
* 流处理层：消费连续事件的产生的数据，主要有三个用途 
  * 持续的将数据在应用程序和系统中移动
  * 聚合并处理事件
  * 在本地维持应用程序的状态

## 2.2 对时间的处理

批处理和流处理的主要区别就在于时间片段上，主要有批处理架构、Lambda 架构以及流处理架构。

<img src="/Users/jingyu/Documents/GitHub/book-note/assets/image-20210330200435180.png" alt="image-20210330200435180" style="zoom:50%;" />

* 批处理架构：批处理形式如上图所示，将数据以一个较长的时间为单位（如一个小时）进行划分，然后将这部分数据作为输入，进行处理。以往的大数据计算都是基于这种模式，但是有着以下问题：
  * 太多独立的部分，这种架构需要动用许多系统
  * 对时间段的划分不明确，如果需要更改时间，则需要更改代码
  * 作业界限的划分做不到清晰

<img src="/Users/jingyu/Documents/GitHub/book-note/assets/image-20210330201847736.png" alt="image-20210330201847736" style="zoom:33%;" />

* lambda 架构：lambda 架构如上图，通过流处理来获取实时的近似结果，再用一段时间的批处理数据获取精确结果对实时结果进行校正

<img src="/Users/jingyu/Documents/GitHub/book-note/assets/image-20210330202115122.png" alt="image-20210330202115122" style="zoom:50%;" />

* 流处理：通过消息队列进行传输，使用流处理器提供流数据（flink），产生的结果即正确，又实时。



在 flink 中，用窗口来对事件进行分组，并将每一组作为整体进行分析（如求和），flink 有几种窗口：

* 时间窗口：支持滚动操作（无 overlap, `   stream.timeWindow(Time.minutes(1))`）和滑动操作（有 overlap, `stream.timeWindow(Time.minutes(1), Time.seconds(30))`）
* 计数窗口：不以时间为计数，而是以记录的数量来限制窗口。但是不如时间窗严谨，限制的窗口数量可能很长时间都达不到，可以通过设定触发超时来解决
* 会话窗口：会话指的是用户的一段活动阶段，其前其后都是非活动阶段，当用户关闭浏览器或者不再交互一段时间后，会话结束。` stream.window(SessionWindows.withGap(Time.minutes(5))` 

由于 kafka 等传输层支持数据流倒回至过去的某个时间，因此可以使得流处理架构有着**时空穿梭**的功能，但是需要注意，想要正确的重新处理数据，流处理器必须支持事件时间。

> 事件时间：事件实际发生的时间，在实际中，每个时间都会带有一个与他相关的时间戳，如哈利波特 1、2、3、4、5、6、7 部中的数字
>
> 处理事件：事件被处理的时间，也就是处理器处理当前事件的具体时间

## 2.3 有状态的计算

### 2.3.1 流计算中的一致性

流计算也是一个典型的分布式系统，当系统发生故障时，和其他分布式系统一样有着一致性方面的问题，在流计算中，一致性被分为以下几个级别：

* At-most-onece：等价于没有正确性，故障发生后，计数结果可能会丢失
* At-least-onece：程序发生故障后，可能会执行重复运算，但绝对不会少算
* Exactly-once：发生故障后，计算结果仍然和正确结果一致

### 2.3.2 flink 怎么实现 exactly-once

flink 通过设置检查点来实现正确的计算结果，flink 确保了检查点处的状态即使遇到程序中断，也是正确的。

<img src="/Users/jingyu/Documents/GitHub/book-note/assets/image-20210331211452881.png" alt="image-20210331211452881" style="zoom:50%;" />

flink 通过 chekpoint barrier（检查点屏障）分隔所有的输入数据，算子将会处理检查点，但不会计算，而是触发检查点相关的行为。当触发检查点时，flink 为计算状态拍下快照，并存储到稳定的存储系统中，如下图所示。

<img src="/Users/jingyu/Documents/GitHub/book-note/assets/image-20210331213831277.png" alt="image-20210331213831277" style="zoom:50%;" />

当出现故障时，就像其他的分布式系统一样，flink 会先从快照中恢复记录，然后重播快照对应偏移之后的数据，保证了分布式系统的正确性，具体如下图。

<img src="/Users/jingyu/Documents/GitHub/book-note/assets/image-20210331214323430.png" alt="image-20210331214323430" style="zoom: 33%;" />

**检查点是 flink 自动生成的，用户还可以有意识的管理版本状态，称为保存点，二者的工作原理完全一致**

### 2.3.3 和数据库交互

常用的架构是 flink 消费消息队列，处理后，输出到存储系统中,那么flink 怎么保证输出到存储系统中的 exactly-once?(*尽管 flink保证了每个数据重演只处理一次,但是已经输出到其他系统的流是没有办法撤回的，因此回滚到上一个检查点间已经输出的数据，在这个层面来说没有办法保证 exactly-onece*)

flink 为了解决这个问题，具体有两种实现方法：

* 第一种方式是在flink 的输出环节，缓冲所有输出，并在 sink 收到检查点后，再将输出**原子提交**到存储系统。
* 第二种方式什么也不做，急切的将数据写入输出存储系统，并牢记这些数据是脏数据。当发生故障时，除了回滚输入和 flink 作业，还需要回滚输出。

上面两种方式，类似于数据库隔离级别中的读已提交和读未提交，可以根据应用程序来选择合适的语义

此外，有些时候，直接查询 flink 端的状态，也可以获得需要查询的内容，但是相比于通用数据库，可查询的状态限制还是较大

## 2.4 批处理

之前的流处理，是通过滑动窗或者滚动窗，对一个无限流入的数据进行处理的。批处理有着以下区别：

* 没有滑动窗或者滚动窗在数据中滑动，而是在一个批次内，使用一个全局窗口
* 在过程中，不会持续生成计算结果，只在末尾生成一次

本质上，批处理是一种特殊的流处理形式，当输入有限时，使用专用的批处理器可能效率更高，但整合进流处理器中，效率也很高。flink 对批处理和流处理有着不同的机制，根据各自的特点来高效的实现各种处理：

* 流处理
  * 检查点以及状态机制：实现容错、有状态的处理
  * 水印机制：实现事件时钟，避免使用物理时钟难以管理版本的问题
  * 窗口和触发器：用于限制计算范围，并定义呈现结果的时间
* 批处理
  * 用于调度和恢复的回溯法
  * 用于散列和排序的特殊内存结构，可以在需要时，将一部分数据溢出到磁盘上
  * 优化器，尽可能缩短生成结果的时间







